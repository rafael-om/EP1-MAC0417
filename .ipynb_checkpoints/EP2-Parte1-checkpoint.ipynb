{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "### EP2 MAC0417 / MAC5768\n",
    "##################################################################\n",
    "# AO PREENCHER ESSE CABEÇALHO COM O MEU NOME E O MEU NÚMERO USP,#\n",
    "# DECLARO QUE SOU O ÚNICO AUTOR E RESPONSÁVEL PELA RESOLUÇÃO #\n",
    "# DESTE EP. #\n",
    "# TODAS AS PARTES FORAM DESENVOLVIDAS E IMPLEMENTADAS POR MIM, #\n",
    "# SEGUINDO AS INSTRUÇÕES E QUE PORTANTO, NÃO CONSTITUEM #\n",
    "# DESONESTIDADE ACADÊMICA OU PLÁGIO. #\n",
    "# #\n",
    "# DECLARO TAMBÉM, QUE SOU RESPONSÁVEL POR TODAS AS CÓPIAS #\n",
    "# DESSE PROGRAMA, E QUE EU NÃO DISTRIBUI OU FACILITEI A #\n",
    "# SUA DISTRIBUIÇÃO. ESTOU CIENTE QUE OS CASOS DE PLÁGIO E #\n",
    "# DESONESTIDADE ACADÊMICA SERÃO TRATADOS SEGUNDO OS CRITÉRIOS #\n",
    "# DEFINIDOS NO CÓDIGO DE ÉTICA DA USP. #\n",
    "# #\n",
    "# ENTENDO QUE JUPYTER NOTEBOOKS SEM ASSINATURA NÃO SERÃO #\n",
    "# CORRIGIDOS E, AINDA ASSIM, PODERÃO SER PUNIDOS POR #\n",
    "# DESONESTIDADE ACADÊMICA. #\n",
    "# #\n",
    "# #\n",
    "# Nome : Rafael de Oliveira Magalhães #\n",
    "# NUSP : 12566122 #\n",
    "# Turma: #\n",
    "# Prof.: Ronaldo Fumio Hashimoto#\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7eed13",
   "metadata": {},
   "source": [
    "# EP2 - Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420cc6b2",
   "metadata": {},
   "source": [
    "Para executar este notebook, basta executar as células sequencialmente.\n",
    "\n",
    "Na transformação do logaritmo utilizou-se log2.\n",
    "\n",
    "Na transformação do laplaciano utilizou-se o filtro com 8 no centro e -1 nas demais posições.\n",
    "\n",
    "No filtro da média utilizou-se um filtro 3x3.\n",
    "\n",
    "Nas transformações do logaritmo e gama, os parâmetros c e gama foram escolhidos para cada imagem, pois notou-se que escolher valores únicos para cada iluminação não produzia bons resultados em todas as imagens, tendo em vista que além da iluminação o fundo também influencia bastante, assim salvou-se estes parâmetros no arquivo augmented.csv, o qual é lido por padrão ao executar estas transformações.\n",
    "\n",
    "Ressalta-se que é importante executar este notebook primeiro, e lembrar de executar as células de criação dos diretórios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1d495",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "493816d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de2869a",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5985b6c",
   "metadata": {},
   "source": [
    "### Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e56c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fd5632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    if os.path.exists(directory):\n",
    "        print(f'O diretório {directory} foi criado com sucesso!')\n",
    "    else:\n",
    "        print(f'Falha ao criar o diretório {directory}. Tente novamente.')\n",
    "        raise InvalidError(\"Falha ao criar diretório\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf33c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs():\n",
    "    directory1 = 'originalGrayDataset'\n",
    "    directory2 = 'augmentedDataSet'\n",
    "    directory3 = 'augmentedDataSet/Contraste'\n",
    "    directory4 = 'augmentedDataSet/Laplaciano'\n",
    "    directory5 = 'augmentedDataSet/Média'\n",
    "    directory6 = 'augmentedDataSet/Logaritmo'\n",
    "    directory7 = 'augmentedDataSet/Gama'\n",
    "    directory8 = 'originalGrayDataset/meanHistogram'\n",
    "    directory9 = 'augmentedDataSet/Contraste/meanHistogram'\n",
    "    directory10 = 'augmentedDataSet/Laplaciano/meanHistogram'\n",
    "    directory11 = 'augmentedDataSet/Média/meanHistogram'\n",
    "    directory12 = 'augmentedDataSet/Logaritmo/meanHistogram'\n",
    "    directory13 = 'augmentedDataSet/Gama/meanHistogram'\n",
    "    directory14 = 'originalGrayDataset/normalizedDataset'\n",
    "    directory15 = 'augmentedDataSet/Contraste/normalizedDataset'\n",
    "    directory16 = 'augmentedDataSet/Laplaciano/normalizedDataset'\n",
    "    directory17 = 'augmentedDataSet/Média/normalizedDataset'\n",
    "    directory18 = 'augmentedDataSet/Logaritmo/normalizedDataset'\n",
    "    directory19 = 'augmentedDataSet/Gama/normalizedDataset'\n",
    "    create_dir(directory1)\n",
    "    create_dir(directory2)\n",
    "    create_dir(directory3)\n",
    "    create_dir(directory4)\n",
    "    create_dir(directory5)\n",
    "    create_dir(directory6)\n",
    "    create_dir(directory7)\n",
    "    create_dir(directory8)\n",
    "    create_dir(directory9)\n",
    "    create_dir(directory10)\n",
    "    create_dir(directory11)\n",
    "    create_dir(directory12)\n",
    "    create_dir(directory13)\n",
    "    create_dir(directory14)\n",
    "    create_dir(directory15)\n",
    "    create_dir(directory16)\n",
    "    create_dir(directory17)\n",
    "    create_dir(directory18)\n",
    "    create_dir(directory19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40facbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O diretório originalGrayDataset foi criado com sucesso!\n",
      "O diretório augmentedDataSet foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Contraste foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Laplaciano foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Média foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Logaritmo foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Gama foi criado com sucesso!\n",
      "O diretório originalGrayDataset/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Contraste/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Laplaciano/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Média/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Logaritmo/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Gama/meanHistogram foi criado com sucesso!\n",
      "O diretório originalGrayDataset/normalizedDataset foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Contraste/normalizedDataset foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Laplaciano/normalizedDataset foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Média/normalizedDataset foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Logaritmo/normalizedDataset foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Gama/normalizedDataset foi criado com sucesso!\n",
      "O diretório originalGrayDataset/normalizedDataset/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Contraste/normalizedDataset/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Laplaciano/normalizedDataset/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Média/normalizedDataset/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Logaritmo/normalizedDataset/meanHistogram foi criado com sucesso!\n",
      "O diretório augmentedDataSet/Gama/normalizedDataset/meanHistogram foi criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "make_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb1730c",
   "metadata": {},
   "source": [
    "### Resize and Convert RGB Image to Gray Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08cac7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    return cv2.resize(img, (0,0), fx=0.5, fy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3638b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf3975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_convert(directory_path=\"Imagens/\", new_directory=\"originalGrayDataset/\"):\n",
    "    files = os.listdir(directory_path)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        resized_image = resize_image(image)\n",
    "        gray_image = rgb_to_gray(resized_image)\n",
    "        new_image_path = os.path.join(new_directory, image_file)\n",
    "        cv2.imwrite(new_image_path, gray_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69a24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d792b076",
   "metadata": {},
   "source": [
    "### Reescale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc033449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reescale(image, upper_bound=255):\n",
    "    normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    norm = normalized_image * upper_bound\n",
    "    return np.round(norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a831157",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6327b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log10_transformation(image, c):\n",
    "    new_image = np.copy(image)\n",
    "    lin, col = image.shape\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            new_image[i][j] = c * math.log(1 + image[i][j])\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef23c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2_transformation(image, c):\n",
    "    new_image = np.copy(image)\n",
    "    lin, col = image.shape\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            new_image[i][j] = c * math.log2(1 + image[i][j])\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5a5bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transformation_reescale(image, c=1):\n",
    "    log_image = log2_transformation(image, c)\n",
    "    return reescale(log_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30daa168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_log(directory_path=\"originalGrayDataset/\", new_directory=\"augmentedDataSet/Logaritmo/\"):\n",
    "    files = os.listdir(directory_path)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "    \n",
    "    parameters = pd.read_csv(\"augmented.csv\")\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        #print(image)\n",
    "        c  = int(parameters[parameters['Arquivo'] == image_file][\"C-Log2\"].iloc[0])\n",
    "        #print(c)\n",
    "        log_image = log_transformation_reescale(image, c)\n",
    "        new_image_path = os.path.join(new_directory, image_file)\n",
    "        \n",
    "        cv2.imwrite(new_image_path, log_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdbc68b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec97c3",
   "metadata": {},
   "source": [
    "### Exponential Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0834891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_transformation(image, c):\n",
    "    new_image = np.copy(image)\n",
    "    lin, col = image.shape\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            new_image[i][j] = c * math.exp(1 + image[i][j])\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_transformation_reescale(image, c=1):\n",
    "    exp_image = exp_transformation(image, c)\n",
    "    return reescale(exp_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e8c30",
   "metadata": {},
   "source": [
    "### Gamma Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ac00c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_transformation(image, c, gamma):\n",
    "    new_image = np.copy(image)\n",
    "    lin, col = image.shape\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            new_image[i][j] = c * image[i][j] ** gamma\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "406da927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_transformation_reescale(image, c=1, gamma=1):\n",
    "    gamma_image = gamma_transformation(image, c, gamma)\n",
    "    return reescale(gamma_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b3a03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gamma(directory_path=\"originalGrayDataset/\", new_directory=\"augmentedDataSet/Gama/\"):\n",
    "    files = os.listdir(directory_path)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "    \n",
    "    parameters = pd.read_csv(\"augmented.csv\")\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        c  = int(parameters[parameters['Arquivo'] == image_file][\"C-Gama\"].iloc[0])\n",
    "        gamma  = parameters[parameters['Arquivo'] == image_file][\"Gama\"].iloc[0]\n",
    "        gamma_image = gamma_transformation_reescale(image, c=c, gamma=gamma)\n",
    "        new_image_path = os.path.join(new_directory, image_file)\n",
    "        \n",
    "        cv2.imwrite(new_image_path, gamma_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "135eb91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gamma()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9765e",
   "metadata": {},
   "source": [
    "### Contrast Stretching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "223fc221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(min_x, min_y, max_x, max_y, x):\n",
    "    a = (max_y - min_y)/(max_x - min_x)\n",
    "    b = max_y - a * max_x\n",
    "    return (a * x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4ec77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_function(image, min_x, min_new_y, max_x, max_new_y):\n",
    "    lin, col = image.shape\n",
    "    new_image = np.zeros((lin, col), dtype=float)\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            pixel = image[i][j]\n",
    "            if pixel < min_x:\n",
    "                new_image[i][j] = linear_function(0, 0, min_x, min_new_y, pixel)\n",
    "            elif min_x <= pixel <= max_x:\n",
    "                new_image[i][j] = linear_function(min_x, min_new_y, max_x, max_new_y, pixel)\n",
    "            else:\n",
    "                new_image[i][j] = linear_function(max_x, max_new_y, 255, 255, pixel)\n",
    "    np.round(new_image).astype(int)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6fd0ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_function(image):\n",
    "    maxx = np.max(image)\n",
    "    minn = np.min(image)\n",
    "    a = 255 / (maxx - minn)\n",
    "    b = (-minn) * a\n",
    "    lin, col = image.shape\n",
    "    new_image = np.zeros((lin, col), dtype=float)\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            new_image[i][j] = a * image[i][j] + b\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d2c332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contrast(directory_path=\"originalGrayDataset/\", new_directory=\"augmentedDataSet/Contraste/\"):\n",
    "    files = os.listdir(directory_path)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        \n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        new_image = reescale(contrast_function(image))\n",
    "        new_image_path = os.path.join(new_directory, image_file)\n",
    "        \n",
    "        cv2.imwrite(new_image_path, new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a04512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7485/1247397169.py:5: RuntimeWarning: overflow encountered in scalar negative\n",
      "  b = (-minn) * a\n"
     ]
    }
   ],
   "source": [
    "run_contrast()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e726eb89",
   "metadata": {},
   "source": [
    "### Convolution and Filters Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc883205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zero_padding(image, length):\n",
    "    return np.pad(image, pad_width=length, mode='constant', constant_values=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4988f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_filter(length):\n",
    "    filterr = np.ones((length,length), dtype=float)\n",
    "    return (1/(length**2)) * filterr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4550774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(image, filterr):\n",
    "    image_lines, image_columns = image.shape\n",
    "    diff = len(filterr)//2\n",
    "    conv_image = np.zeros((image_lines, image_columns))\n",
    "    padding_image = add_zero_padding(image, diff)\n",
    "    for i in range(image_lines):\n",
    "        for j in range(image_columns):\n",
    "            sub_matrix = padding_image[i:i+len(filterr), j:j+len(filterr)]\n",
    "            conv_image[i, j] = np.sum(sub_matrix * filterr)\n",
    "    return conv_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c381c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_filter(image, filter_size):\n",
    "    filterr = create_mean_filter(filter_size)\n",
    "    return convolution(image, filterr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c7eeec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_laplacian_filter():\n",
    "    return np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daf49d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_laplacian_filter():\n",
    "    return np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "789cc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_filter(image):\n",
    "    filterr = create_laplacian_filter()\n",
    "    return convolution(image, filterr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cc5bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_laplacian(directory_path=\"originalGrayDataset/\", new_directory=\"augmentedDataSet/Laplaciano/\"):\n",
    "    files = os.listdir(directory_path)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        \n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        laplacian = laplacian_filter(image)\n",
    "        laplacian_image = reescale(laplacian)\n",
    "        new_image_path = os.path.join(new_directory, image_file)\n",
    "        cv2.imwrite(new_image_path, laplacian_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a979a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_laplacian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac08970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mean_filter(filter_size, directory_path=\"originalGrayDataset/\", new_directory=\"augmentedDataSet/Média/\"):\n",
    "    files = os.listdir(directory_path)\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        \n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mean_image = mean_filter(image, filter_size)\n",
    "        mean_image = reescale(mean_image)\n",
    "        new_image_path = os.path.join(new_directory, image_file)\n",
    "        \n",
    "        cv2.imwrite(new_image_path, mean_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d603e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mean_filter(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46f0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
