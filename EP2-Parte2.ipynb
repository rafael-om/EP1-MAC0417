{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991df15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "### EP2 MAC0417 / MAC5768\n",
    "##################################################################\n",
    "# AO PREENCHER ESSE CABEÇALHO COM O MEU NOME E O MEU NÚMERO USP,#\n",
    "# DECLARO QUE SOU O ÚNICO AUTOR E RESPONSÁVEL PELA RESOLUÇÃO #\n",
    "# DESTE EP. #\n",
    "# TODAS AS PARTES FORAM DESENVOLVIDAS E IMPLEMENTADAS POR MIM, #\n",
    "# SEGUINDO AS INSTRUÇÕES E QUE PORTANTO, NÃO CONSTITUEM #\n",
    "# DESONESTIDADE ACADÊMICA OU PLÁGIO. #\n",
    "# #\n",
    "# DECLARO TAMBÉM, QUE SOU RESPONSÁVEL POR TODAS AS CÓPIAS #\n",
    "# DESSE PROGRAMA, E QUE EU NÃO DISTRIBUI OU FACILITEI A #\n",
    "# SUA DISTRIBUIÇÃO. ESTOU CIENTE QUE OS CASOS DE PLÁGIO E #\n",
    "# DESONESTIDADE ACADÊMICA SERÃO TRATADOS SEGUNDO OS CRITÉRIOS #\n",
    "# DEFINIDOS NO CÓDIGO DE ÉTICA DA USP. #\n",
    "# #\n",
    "# ENTENDO QUE JUPYTER NOTEBOOKS SEM ASSINATURA NÃO SERÃO #\n",
    "# CORRIGIDOS E, AINDA ASSIM, PODERÃO SER PUNIDOS POR #\n",
    "# DESONESTIDADE ACADÊMICA. #\n",
    "# #\n",
    "# #\n",
    "# Nome : Rafael de Oliveira Magalhães #\n",
    "# NUSP : 12566122 #\n",
    "# Turma: #\n",
    "# Prof.: Ronaldo Fumio Hashimoto#\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d4fcd",
   "metadata": {},
   "source": [
    "# EP2 - Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6420c8",
   "metadata": {},
   "source": [
    "Para executar este notebook basta executar as células sequencialmente.\n",
    "\n",
    "O comando run_equalization() executará a normalização em todos os datasets.\n",
    "\n",
    "Por fim, para visualizar os resultados, basta executar os comandos ao fim para cada dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d74764",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bf8eb",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab0e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_transformation(image):\n",
    "    dict_hist = {}\n",
    "    new_hist = {}\n",
    "    lin, col = image.shape\n",
    "    for i in range(256):\n",
    "        dict_hist[i] = 0\n",
    "        new_hist[i] = 0\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            dict_hist[int(image[i][j])] += 1\n",
    "    for i in range(256):\n",
    "        dict_hist[i] /= (lin * col)\n",
    "    for i in range(256):\n",
    "        value = 0.0\n",
    "        for j in range(i + 1):\n",
    "            value += dict_hist[j]\n",
    "        new_hist[i] = 255 * value\n",
    "\n",
    "    new_image = np.zeros((lin, col), dtype=float)\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            new_image[i][j] = new_hist[int(image[i][j])]\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfe05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_equalization():\n",
    "    directories = ['originalGrayDataset/', \n",
    "                   'augmentedDataSet/Laplaciano/', \n",
    "                   'augmentedDataSet/Média/',\n",
    "                   'augmentedDataSet/Contraste/',\n",
    "                   'augmentedDataSet/Gama/',\n",
    "                   'augmentedDataSet/Logaritmo/']\n",
    "    new_directory=\"normalizedDataset/\"\n",
    "    for directory in directories:\n",
    "        directory_destiny = directory + new_directory\n",
    "        files = os.listdir(directory)\n",
    "        image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "        image_files = [file for file in files if file.lower().endswith(image_extensions)]\n",
    "\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(directory, image_file)\n",
    "\n",
    "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            new_image = histogram_transformation(image)\n",
    "            new_image_path = os.path.join(directory_destiny, image_file)\n",
    "\n",
    "            cv2.imwrite(new_image_path, new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf491f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(image, title):\n",
    "    pixels = []\n",
    "    quantity = []\n",
    "    lin, col = image.shape\n",
    "    for i in range(256):\n",
    "        pixels.append(i)\n",
    "        quantity.append(0)\n",
    "    for i in range(lin):\n",
    "        for j in range(col):\n",
    "            quantity[int(image[i][j])] += 1\n",
    "    plt.plot(pixels, quantity)\n",
    "    plt.title('Histograma' + title)\n",
    "    plt.xlabel('Faixa de Intensidade dos Pixels')\n",
    "    plt.ylabel('Ocorrências')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_histogram(image, bins=256, interval=(0, 256)):\n",
    "    histogram, _ = np.histogram(image, bins=bins, range=interval)\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_histogram(directory_path: str, metadata_file=\"imagens_metadados.csv\"):\n",
    "    csv_file = pd.read_csv(metadata_file)\n",
    "    unique_ilumination = pd.unique(csv_file['Iluminação'])\n",
    "    for ilumination in unique_ilumination:\n",
    "        filtered_csv = csv_file[csv_file['Iluminação'] == ilumination]\n",
    "        histogram1 = np.zeros(256, dtype=float)\n",
    "        histogram2 = np.zeros(256, dtype=float)\n",
    "        for i in range(len(filtered_csv)):\n",
    "            image_file = filtered_csv.iloc[i]['Arquivo']\n",
    "            image_path = os.path.join(directory_path, image_file)\n",
    "            image_path2 = os.path.join(directory_path+\"normalizedDataset/\", image_file)\n",
    "            image1 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n",
    "            histogram1 += calculate_histogram(image1)\n",
    "            histogram2 += calculate_histogram(image2)\n",
    "        histogram1 /= len(filtered_csv)\n",
    "        histogram1 /= sum(histogram1)\n",
    "        histogram2 /= sum(histogram2)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.bar(range(len(histogram1)), histogram1, width=1.0, edgecolor='gray')\n",
    "        ax1.set_title('Não Equalizado')\n",
    "        ax1.set_xlabel('Intensidade do Pixel')\n",
    "        ax1.set_ylabel('Frequência Média')\n",
    "        \n",
    "        ax2.bar(range(len(histogram2)), histogram2, width=1.0, edgecolor='gray')\n",
    "        ax2.set_title('Equalizado')\n",
    "        ax2.set_xlabel('Intensidade do Pixel')\n",
    "        ax2.set_ylabel('Frequência Média')\n",
    "        fig.suptitle(f'Histograma Médio - Iluminação = {ilumination}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        histogram_file = directory_path + f\"meanHistogram/histogram_{ilumination}.png\"\n",
    "        plt.savefig(histogram_file)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b097f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_image(directory_path: str, metadata_file=\"imagens_metadados.csv\"):\n",
    "    csv_file = pd.read_csv(metadata_file)\n",
    "    unique_ilumination = pd.unique(csv_file['Iluminação'])\n",
    "    for ilumination in unique_ilumination:\n",
    "        filtered_csv = csv_file[csv_file['Iluminação'] == ilumination]\n",
    "        N = len(filtered_csv)\n",
    "        index = np.random.randint(N)\n",
    "        image_file = filtered_csv.iloc[index]['Arquivo']\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        image_path2 = os.path.join(directory_path+\"normalizedDataset/\", image_file)\n",
    "        image1 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        ax1.imshow(image1, cmap=\"gray\")\n",
    "        ax1.set_title('Não Equalizado')\n",
    "        \n",
    "        ax2.imshow(image2, cmap=\"gray\")\n",
    "        ax2.set_title('Equalizado')\n",
    "        fig.suptitle(f'Imagens de Exemplo - Iluminação = {ilumination}', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.95)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec009a",
   "metadata": {},
   "source": [
    "## Run Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_equalization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796c9f8",
   "metadata": {},
   "source": [
    "## Dataset Equalization Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdd598d",
   "metadata": {},
   "source": [
    "Agruparemos a análise conforme os resultados observados nos datasets.\n",
    "\n",
    "### Transformação do Logaritmo, Gama\n",
    "\n",
    "Nestes datasets a equalização do histograma aumentou o contraste entre os objetos e o fundo, porém em apenas poucas imagens o resultado foi bom. porém de forma exagerada, Na maioria das imagens o contraste aumentou demais, piorando a nitidez, realçando ruídos e mascarando detalhes dos objetos. No caso da iluminação \"flash\", o resultado apesar de pior não foi tão ruim em comparação com as demais iluminações. Além disso também houveram algumas imagens com pouca piora nas iluminações \"dia\" e \"noite\" dependendo do fundo. \n",
    "\n",
    "Por fim, cita-se também que, no caso das iluminações claras, os objetos ficaram muito escuros e nas iluminações escuras os objetos ficaram muito claros.\n",
    "\n",
    "### Filtro da Média, Contrast Stretching e Dataset Original Cinza\n",
    "\n",
    "Nesses datasets a equalização também produziu os mesmos efeitos descritos no caso anterior, a diferença é que estas 3 transformações não geraram imagens mais claras em todas as iluminações, portanto as iluminações \"flash\" e \"noite\" continuaram muito escuras, o que resultou em um contraste ainda mais intenso após a equalização de histograma, ressaltando diversos detalhes dos fundos e de pequenas diferenças de valores entre pixels vizinhos.\n",
    "\n",
    "### Laplaciano\n",
    "\n",
    "Neste caso a equalização do histograma obteve bons resultados na maioria dos casos, no sentido de realçar e destacar os objetos e as bordas, tendo em vista que nas imagens correspondentes aos laplacianos, o contraste entre o fundo e os objetos é muito pequeno sendo que em várias imagens não é possível distinguir os objetos. No entanto, embora a equalização tenha realçado os objetos, os detalhes dos fundos também foram destacados o que pode ser indesejado. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba992e99",
   "metadata": {},
   "source": [
    "## Log Images and Mean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98187806",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mean_image(\"augmentedDataSet/Logaritmo/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fc9f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_histogram(\"augmentedDataSet/Logaritmo/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca43f0",
   "metadata": {},
   "source": [
    "## Gamma Images and Mean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ab8cab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mean_image(\"augmentedDataSet/Gama/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e0b83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_histogram(\"augmentedDataSet/Gama/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56fcc5",
   "metadata": {},
   "source": [
    "## Mean Images and Mean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de503f0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mean_image(\"augmentedDataSet/Média/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a5620",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_histogram(\"augmentedDataSet/Média/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a2d55f",
   "metadata": {},
   "source": [
    "## Contrast Images and Mean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7a356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mean_image(\"augmentedDataSet/Contraste/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dca084",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_histogram(\"augmentedDataSet/Contraste/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89583668",
   "metadata": {},
   "source": [
    "## Laplacian Images and Mean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0193acb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mean_image(\"augmentedDataSet/Laplaciano/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b309230b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_histogram(\"augmentedDataSet/Laplaciano/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8389f8",
   "metadata": {},
   "source": [
    "## Original Gray Images and Mean Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da52c1d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_mean_image(\"originalGrayDataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb47fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mean_histogram(\"originalGrayDataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cb46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
